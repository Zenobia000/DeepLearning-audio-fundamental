{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 雜訊抑制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1. 預處理：使用濾波器去除低頻和高頻雜訊\n",
    "\n",
    "- 低通濾波器（Low-Pass Filter）：去除高頻噪音，保留低頻信號部分，這對於高頻噪音較多的信號很有效。\n",
    "- 高通濾波器（High-Pass Filter）：去除低頻噪音，保留高頻信號部分，適合去除低頻背景噪音。\n",
    "- 帶通濾波器（Band-Pass Filter）：根據你的信號特性，使用帶通濾波器僅保留信號的特定頻率範圍，去除非目標頻段的噪音。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# 設置濾波器參數\n",
    "lowcut = 300.0\n",
    "highcut = 3000.0\n",
    "fs = 44100\n",
    "\n",
    "# 應用濾波器\n",
    "filtered_signal = bandpass_filter(signal, lowcut, highcut, fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用移動平均或其他平滑技術\n",
    "\n",
    "- 移動平均（Moving Average）：使用移動平均技術對信號進行平滑處理，可以減少雜訊的影響，保留主要波形特徵。\n",
    "- 指數平滑（Exponential Smoothing）：適合於信號波動較大的情況，能更快響應信號變化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(signal, window_size):\n",
    "    return np.convolve(signal, np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "# 應用移動平均\n",
    "smoothed_signal = moving_average(filtered_signal, window_size=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 基於頻率域的處理\n",
    "- 短時傅立葉變換（STFT）：將信號轉換到頻率域進行分析，去除特定頻段的噪音。STFT能幫助識別並分離不同頻率分量。\n",
    "- 小波變換（Wavelet Transform）：使用小波變換來進行多尺度分析，這種方法在去除噪音和提取特定信號方面具有良好的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# 計算STFT\n",
    "D = librosa.stft(filtered_signal)\n",
    "\n",
    "# 將頻譜中的噪音部分置零\n",
    "threshold = np.median(np.abs(D))\n",
    "D[np.abs(D) < threshold] = 0\n",
    "\n",
    "# 重建信號\n",
    "denoised_signal = librosa.istft(D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 使用自適應濾波器（Adaptive Filtering）\n",
    "- 自適應濾波器可以根據輸入信號的特性動態調整其濾波器係數，是去除噪音的有效方法之一。常用的方法包括LMS（Least Mean Squares）濾波器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import lfilter\n",
    "\n",
    "def adaptive_filter(noisy_signal, desired_signal, mu=0.01, n=32):\n",
    "    w = np.zeros(n)\n",
    "    y = np.zeros(len(noisy_signal))\n",
    "    e = np.zeros(len(noisy_signal))\n",
    "    for i in range(n, len(noisy_signal)):\n",
    "        x = noisy_signal[i:i-n:-1]\n",
    "        y[i] = np.dot(w, x)\n",
    "        e[i] = desired_signal[i] - y[i]\n",
    "        w = w + 2 * mu * e[i] * x\n",
    "    return e\n",
    "\n",
    "# 假設desired_signal是理想信號\n",
    "denoised_signal = adaptive_filter(noisy_signal=filtered_signal, desired_signal=desired_signal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 採用機器學習和深度學習方法\n",
    "- 降噪自動編碼器（Denoising Autoencoder）：使用自動編碼器模型學習如何將噪音信號轉換為無噪音的信號。\n",
    "- 深度卷積神經網絡（CNN）：訓練CNN模型來識別和去除噪音。\n",
    "\n",
    "1. 設計CNN架構<br>\n",
    "CNN去噪器的基本結構通常包括以下幾個主要部分：<br>\n",
    "輸入層：接受噪音音頻信號或其頻譜表示（如梅爾頻譜、STFT頻譜等）。<br>\n",
    "卷積層：提取信號中的局部特徵，識別噪音和信號的區別。<br>\n",
    "池化層（可選）：進行降維，保留重要特徵，同時減少計算量。<br>\n",
    "上採樣層：在使用池化層的情況下，進行上採樣以恢復信號的原始大小。<br>\n",
    "輸出層：生成去噪後的音頻信號或其頻譜。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, UpSampling1D, Dense, Flatten, Reshape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Encoder\n",
    "model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same', input_shape=(input_length, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "\n",
    "model.add(Conv1D(8, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "\n",
    "# Decoder\n",
    "model.add(Conv1D(8, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(UpSampling1D(size=2))\n",
    "\n",
    "model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(UpSampling1D(size=2))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Conv1D(1, kernel_size=3, activation='sigmoid', padding='same'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 準備訓練數據\n",
    "- 噪音數據集：需要準備一組含有噪音的音頻數據，以及相應的無噪音版本作為標籤。這些數據可以是真實的錄音，也可以是合成的。<br>\n",
    "- 數據預處理：對音頻信號進行標準化、分幀處理，或者將其轉換為頻譜表示（如STFT或梅爾頻譜）以作為CNN的輸入。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def prepare_data(noisy_signals, clean_signals):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for noisy, clean in zip(noisy_signals, clean_signals):\n",
    "        # 可以使用 librosa 提取特徵，如 STFT 或 MFCC\n",
    "        noisy_stft = librosa.stft(noisy)\n",
    "        clean_stft = librosa.stft(clean)\n",
    "        \n",
    "        X.append(np.abs(noisy_stft))\n",
    "        Y.append(np.abs(clean_stft))\n",
    "    \n",
    "    X = np.array(X).reshape(len(X), X[0].shape[0], X[0].shape[1], 1)\n",
    "    Y = np.array(Y).reshape(len(Y), Y[0].shape[0], Y[0].shape[1], 1)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X_train, Y_train = prepare_data(noisy_signals_train, clean_signals_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 訓練模型\n",
    "- 損失函數：通常使用均方誤差（MSE）作為損失函數來度量去噪效果的好壞。\n",
    "- 優化器：使用 Adam 或其他適合的優化器進行模型訓練。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=50, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 評估模型\n",
    "- 使用測試數據進行評估：對於未見過的噪音信號，檢查模型的去噪效果。\n",
    "- 指標：使用信噪比（SNR）、均方誤差（MSE）、感知評估指標（PESQ）等來評估去噪效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(X_test, Y_test)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Example to denoise\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "\n",
    "# Example to denoise\n",
    "predicted_clean_signal = model.predict(noisy_signal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_signal = model.predict(new_noisy_signal)\n",
    "\n",
    "# 假設已經有 denoised_stft 由 model 預測得到\n",
    "denoised_signal = librosa.istft(denoised_stft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 根據先驗知識進行手動分析和剪切\n",
    "當自動方法難以有效去除噪音時，可以依賴先驗知識（例如音樂的特定頻率範圍或語音信號的特徵）來手動切割和選擇信號部分。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
